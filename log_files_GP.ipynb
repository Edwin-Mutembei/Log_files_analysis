{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Steps\n",
    "1. Identify log files\\\n",
    "Determine the paths to the log files for each core service\n",
    "2. Read log files\\\n",
    "Use python's file I/O (input/output) operations to read the contents of each log file into memory. You can use the 'open()' function to open a file and read its contents.\n",
    "3. Parse log entries\\\n",
    "Parse each error logs file's contents to identify fatal errr logs and scripts error logs. You can use regular expressions ('re' module) or string manipulation techniques to extract relevant log entries based on specific patterns or keywords indicative of fatal errors or script errors.\n",
    "4. Filter logs by core services\\\n",
    "For each log entry extracted,identify the core service it belongs to by examining the path or filename. Only keep log entries that belong to the specified core services.\n",
    "5. Analyze logs\\\n",
    "This may involve counting the occurences of specific types of errors, aggregating statistics or generating reports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log file not found for coresession\n",
      "Log file not found for config\n",
      "Log file not found for finlistival\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "# Define paths to log files for each core service\n",
    "log_paths = {\n",
    "    'coresession': '/path/to/coresession/bin/log/file.log', #input the actual file path here\n",
    "    'config': '/path/to/config/bin/log/file.log', #input the actual file path here\n",
    "    'finlistival': '/path/to/finlistival/bin/log/file.log', #input the actual file path here\n",
    "}\n",
    "\n",
    "# Define regular expressions for identifying fatal error logs and script error logs\n",
    "fatal_error_pattern = re.compile(r'FATAL ERROR:', re.IGNORECASE)\n",
    "script_error_pattern = re.compile(r'SCRIPT ERROR:', re.IGNORECASE)\n",
    "\n",
    "\n",
    "# Define file pahs for filtered logs\n",
    "fatal_log_file = 'fatal_logs.txt'\n",
    "script_error_file = 'scritp_error_logs.txt'\n",
    "\n",
    "#Define a function to extract information from log entry\n",
    "def extract_info_from_entry(entry):\n",
    "    # Extract timestamp, user ID, and message from log entry\n",
    "    timestamp = re.search(r'Date: \\[(.*?)\\]', entry).group(1)\n",
    "    user_id = re.search(r'User ID: \\[(.*?)\\]', entry).group(1)\n",
    "    message = re.search(r'Message: \\[(.*?)\\]', entry).group(1)\n",
    "    return timestamp, user_id, message\n",
    "\n",
    "\n",
    "# Iterate over log files for each core service\n",
    "for service, log_file in log_paths.items():\n",
    "    # Check if log file exists\n",
    "    if os.path.exists(log_file):\n",
    "        with open(log_file, 'r') as f:\n",
    "            # Read log file contents\n",
    "            log_content = f.read()\n",
    "            # Split log file contents into individual log entries\n",
    "            log_entries = log_content.split('= * 50\\n')\n",
    "            # Iterate over log_entries:\n",
    "            for entry in log_entries:\n",
    "                # Check if the entry contains fatal error or script \n",
    "                if fatal_error_pattern.search(entry):\n",
    "                    #process fatal error log entry\n",
    "                    #Extract relevant information or perform analysis\n",
    "                    timestamp, user_id, message = extract_info_from_entry(entry)\n",
    "                    with open(fatal_log_file, 'a') as fatal_f:\n",
    "                        fatal_f.write(f'Timestamp: {timestamp}\\nUser ID: {user_id}\\nMessage: {message}\\n ')\n",
    "\n",
    "                elif script_error_pattern(entry):\n",
    "                    # process script error log entry\n",
    "                    # Extract relevantinformation or perform analysis\n",
    "                    timestamp, user_id, message = extract_info_from_entry(entry)\n",
    "                    with open(script_error_file, 'a') as script_error_f:\n",
    "                        script_error_f.write(f'Timestamp: {timestamp}\\nUser ID: {user_id}\\nMessage: {message}\\n')\n",
    "\n",
    "                else:\n",
    "                    # Skip log entry if it doesn't match any patterns\n",
    "                    continue\n",
    "    else:\n",
    "        print(f'Log file not found for {service}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 'log_paths' dictionary contains paths to log files for each core service\n",
    "- Regular expressions 'fatal-error_pattern' and 'script_error_pattern' are used to identify fatal error logs and script error logs, respectively.\n",
    "- The code iterates over each log file, reads its contents, and split it into individual log entries.\n",
    "- Each log entry is the checked against the regular expressions to identify fatal error logs and scripts error logs.\n",
    "- We define two new file paths, 'fatal_log_file' and 'script_error_file', to store the filtered logs.\n",
    "- We use the 'extract_info_from_entry()' function to extract the timestamp, user ID and message from each log entry.\n",
    "- For each log entry, we write the extracted information to the appropriate file based on whether its fatal error or a script error.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
